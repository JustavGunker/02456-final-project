Loading CUDA module...
Loading Conda...
Environment 'MBML' activated.
Starting Python script...
Using device: cuda
Using device: cuda
Using device: cuda
/zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Task03_Liver_rs
/zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Task03_Liver_rs
Found 28 image/label pairs.
--- success ---
Found 119 unlabeled images.
--- success ---
--- PHASE 1: Pre-training Autoencoder ---

--- Pre-train Epoch 1/200 ---
Batch 0 | Recon Loss: 0.1353

--- Pre-train Epoch 2/200 ---

--- Pre-train Epoch 3/200 ---

--- Pre-train Epoch 4/200 ---

--- Pre-train Epoch 5/200 ---

--- Pre-train Epoch 6/200 ---

--- Pre-train Epoch 7/200 ---

--- Pre-train Epoch 8/200 ---

--- Pre-train Epoch 9/200 ---

--- Pre-train Epoch 10/200 ---

--- Pre-train Epoch 11/200 ---

--- Pre-train Epoch 12/200 ---

--- Pre-train Epoch 13/200 ---

--- Pre-train Epoch 14/200 ---

--- Pre-train Epoch 15/200 ---

--- Pre-train Epoch 16/200 ---

--- Pre-train Epoch 17/200 ---

--- Pre-train Epoch 18/200 ---

--- Pre-train Epoch 19/200 ---

--- Pre-train Epoch 20/200 ---

--- Pre-train Epoch 21/200 ---

--- Pre-train Epoch 22/200 ---

--- Pre-train Epoch 23/200 ---

--- Pre-train Epoch 24/200 ---

--- Pre-train Epoch 25/200 ---

--- Pre-train Epoch 26/200 ---

--- Pre-train Epoch 27/200 ---

--- Pre-train Epoch 28/200 ---

--- Pre-train Epoch 29/200 ---

--- Pre-train Epoch 30/200 ---

--- Pre-train Epoch 31/200 ---

--- Pre-train Epoch 32/200 ---

--- Pre-train Epoch 33/200 ---

--- Pre-train Epoch 34/200 ---

--- Pre-train Epoch 35/200 ---

--- Pre-train Epoch 36/200 ---

--- Pre-train Epoch 37/200 ---

--- Pre-train Epoch 38/200 ---

--- Pre-train Epoch 39/200 ---

--- Pre-train Epoch 40/200 ---

--- Pre-train Epoch 41/200 ---

--- Pre-train Epoch 42/200 ---

--- Pre-train Epoch 43/200 ---

--- Pre-train Epoch 44/200 ---

--- Pre-train Epoch 45/200 ---

--- Pre-train Epoch 46/200 ---

--- Pre-train Epoch 47/200 ---

--- Pre-train Epoch 48/200 ---

--- Pre-train Epoch 49/200 ---

--- Pre-train Epoch 50/200 ---

--- Pre-train Epoch 51/200 ---

--- Pre-train Epoch 52/200 ---

--- Pre-train Epoch 53/200 ---

--- Pre-train Epoch 54/200 ---

--- Pre-train Epoch 55/200 ---

--- Pre-train Epoch 56/200 ---

--- Pre-train Epoch 57/200 ---

--- Pre-train Epoch 58/200 ---

--- Pre-train Epoch 59/200 ---

--- Pre-train Epoch 60/200 ---

--- Pre-train Epoch 61/200 ---

--- Pre-train Epoch 62/200 ---

--- Pre-train Epoch 63/200 ---

--- Pre-train Epoch 64/200 ---

--- Pre-train Epoch 65/200 ---

--- Pre-train Epoch 66/200 ---

--- Pre-train Epoch 67/200 ---

--- Pre-train Epoch 68/200 ---

--- Pre-train Epoch 69/200 ---

--- Pre-train Epoch 70/200 ---

--- Pre-train Epoch 71/200 ---

--- Pre-train Epoch 72/200 ---

--- Pre-train Epoch 73/200 ---

--- Pre-train Epoch 74/200 ---

--- Pre-train Epoch 75/200 ---

--- Pre-train Epoch 76/200 ---

--- Pre-train Epoch 77/200 ---

--- Pre-train Epoch 78/200 ---

--- Pre-train Epoch 79/200 ---

--- Pre-train Epoch 80/200 ---

--- Pre-train Epoch 81/200 ---

--- Pre-train Epoch 82/200 ---

--- Pre-train Epoch 83/200 ---

--- Pre-train Epoch 84/200 ---

--- Pre-train Epoch 85/200 ---

--- Pre-train Epoch 86/200 ---

--- Pre-train Epoch 87/200 ---

--- Pre-train Epoch 88/200 ---

--- Pre-train Epoch 89/200 ---

--- Pre-train Epoch 90/200 ---

--- Pre-train Epoch 91/200 ---

--- Pre-train Epoch 92/200 ---

--- Pre-train Epoch 93/200 ---

--- Pre-train Epoch 94/200 ---

--- Pre-train Epoch 95/200 ---

--- Pre-train Epoch 96/200 ---

--- Pre-train Epoch 97/200 ---

--- Pre-train Epoch 98/200 ---

--- Pre-train Epoch 99/200 ---

--- Pre-train Epoch 100/200 ---

--- Pre-train Epoch 101/200 ---

--- Pre-train Epoch 102/200 ---

--- Pre-train Epoch 103/200 ---

--- Pre-train Epoch 104/200 ---

--- Pre-train Epoch 105/200 ---

--- Pre-train Epoch 106/200 ---

--- Pre-train Epoch 107/200 ---

--- Pre-train Epoch 108/200 ---

--- Pre-train Epoch 109/200 ---

--- Pre-train Epoch 110/200 ---

--- Pre-train Epoch 111/200 ---

--- Pre-train Epoch 112/200 ---

--- Pre-train Epoch 113/200 ---

--- Pre-train Epoch 114/200 ---

--- Pre-train Epoch 115/200 ---

--- Pre-train Epoch 116/200 ---

--- Pre-train Epoch 117/200 ---

--- Pre-train Epoch 118/200 ---

--- Pre-train Epoch 119/200 ---

--- Pre-train Epoch 120/200 ---

--- Pre-train Epoch 121/200 ---

--- Pre-train Epoch 122/200 ---

--- Pre-train Epoch 123/200 ---

--- Pre-train Epoch 124/200 ---

--- Pre-train Epoch 125/200 ---

--- Pre-train Epoch 126/200 ---

--- Pre-train Epoch 127/200 ---

--- Pre-train Epoch 128/200 ---

--- Pre-train Epoch 129/200 ---

--- Pre-train Epoch 130/200 ---

--- Pre-train Epoch 131/200 ---

--- Pre-train Epoch 132/200 ---

--- Pre-train Epoch 133/200 ---

--- Pre-train Epoch 134/200 ---

--- Pre-train Epoch 135/200 ---

--- Pre-train Epoch 136/200 ---

--- Pre-train Epoch 137/200 ---

--- Pre-train Epoch 138/200 ---

--- Pre-train Epoch 139/200 ---

--- Pre-train Epoch 140/200 ---

--- Pre-train Epoch 141/200 ---

--- Pre-train Epoch 142/200 ---

--- Pre-train Epoch 143/200 ---

--- Pre-train Epoch 144/200 ---

--- Pre-train Epoch 145/200 ---

--- Pre-train Epoch 146/200 ---

--- Pre-train Epoch 147/200 ---

--- Pre-train Epoch 148/200 ---

--- Pre-train Epoch 149/200 ---

--- Pre-train Epoch 150/200 ---

--- Pre-train Epoch 151/200 ---

--- Pre-train Epoch 152/200 ---

--- Pre-train Epoch 153/200 ---

--- Pre-train Epoch 154/200 ---

--- Pre-train Epoch 155/200 ---

--- Pre-train Epoch 156/200 ---

--- Pre-train Epoch 157/200 ---

--- Pre-train Epoch 158/200 ---

--- Pre-train Epoch 159/200 ---

--- Pre-train Epoch 160/200 ---

--- Pre-train Epoch 161/200 ---

--- Pre-train Epoch 162/200 ---

--- Pre-train Epoch 163/200 ---

--- Pre-train Epoch 164/200 ---

--- Pre-train Epoch 165/200 ---

--- Pre-train Epoch 166/200 ---

--- Pre-train Epoch 167/200 ---

--- Pre-train Epoch 168/200 ---

--- Pre-train Epoch 169/200 ---

--- Pre-train Epoch 170/200 ---

--- Pre-train Epoch 171/200 ---

--- Pre-train Epoch 172/200 ---

--- Pre-train Epoch 173/200 ---

--- Pre-train Epoch 174/200 ---

--- Pre-train Epoch 175/200 ---

--- Pre-train Epoch 176/200 ---

--- Pre-train Epoch 177/200 ---

--- Pre-train Epoch 178/200 ---

--- Pre-train Epoch 179/200 ---

--- Pre-train Epoch 180/200 ---

--- Pre-train Epoch 181/200 ---

--- Pre-train Epoch 182/200 ---

--- Pre-train Epoch 183/200 ---

--- Pre-train Epoch 184/200 ---

--- Pre-train Epoch 185/200 ---

--- Pre-train Epoch 186/200 ---

--- Pre-train Epoch 187/200 ---

--- Pre-train Epoch 188/200 ---

--- Pre-train Epoch 189/200 ---

--- Pre-train Epoch 190/200 ---

--- Pre-train Epoch 191/200 ---

--- Pre-train Epoch 192/200 ---

--- Pre-train Epoch 193/200 ---

--- Pre-train Epoch 194/200 ---

--- Pre-train Epoch 195/200 ---

--- Pre-train Epoch 196/200 ---

--- Pre-train Epoch 197/200 ---

--- Pre-train Epoch 198/200 ---

--- Pre-train Epoch 199/200 ---

--- Pre-train Epoch 200/200 ---
--- Pre-training Finished ---
Saving encoder weights to /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Trained_models/pretrained_ae_encoder.pth
Job Finished.

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27018696: <pretain_AE_job> in cluster <dcc> Done

Job <pretain_AE_job> was submitted from host <gbarlogin1> by user <s214776> in cluster <dcc> at Fri Nov 14 20:02:29 2025
Job was executed on host(s) <4*n-62-18-4>, in queue <gpua40>, as user <s214776> in cluster <dcc> at Fri Nov 14 20:34:37 2025
</zhome/d2/4/167803> was used as the home directory.
</zhome/d2/4/167803/Desktop/Deep_project/02456-final-project> was used as the working directory.
Started at Fri Nov 14 20:34:37 2025
Terminated at Fri Nov 14 20:35:06 2025
Results reported at Fri Nov 14 20:35:06 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
### --- Job Name ---
#BSUB -J pretain_AE_job

### --- Log files ---
#BSUB -o /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_%J.out
#BSUB -e /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_%J.err
### --- Resource Requests ---
#BSUB -q gpua40             # Request GPU queue
#BSUB -gpu "num=1:mode=exclusive_process" # Request 1 GPU, all to myself
#BSUB -n 4                    # Request 4 CPU cores
#BSUB -R "rusage[mem=16GB]"   # Request 16GB memory
#BSUB -W 04:00                # 4 hour runtime limit

### --- Setup Environment ---
echo "Loading CUDA module..."
module load cuda/11.6         # Load CUDA module

echo "Loading Conda..."
# This is the full, correct path to your environment
source /zhome/d2/4/167803/miniforge3/bin/activate MBML
echo "Environment 'MBML' activated."

### --- Run Script ---
echo "Starting Python script..."
python /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Model/pretrain_AE.py

echo "Job Finished."
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   23.51 sec.
    Max Memory :                                 912 MB
    Average Memory :                             802.33 MB
    Total Requested Memory :                     65536.00 MB
    Delta Memory :                               64624.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   30 sec.
    Turnaround time :                            1957 sec.

The output (if any) is above this job summary.



PS:

Read file </zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_27018696.err> for stderr output of this job.

