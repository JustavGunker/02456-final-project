Loading CUDA module...
Loading Conda...
Environment 'MBML' activated.
Starting Python script...
Using device: cuda
Using device: cuda
Found 28 image/label pairs.
--- success ---
Found 119 unlabeled images.
--- success ---
Pre-training Autoencoder

--- Pre-train Epoch 1/100 ---
Batch 0 | Recon Loss: 0.1878
Batch 35 | Recon Loss: 0.0369
Batch 70 | Recon Loss: 0.0157
Avg Epoch loss: 0.0493

--- Pre-train Epoch 2/100 ---
Batch 0 | Recon Loss: 0.0164
Batch 35 | Recon Loss: 0.0081
Batch 70 | Recon Loss: 0.0058
Avg Epoch loss: 0.0148

--- Pre-train Epoch 3/100 ---
Batch 0 | Recon Loss: 0.0100
Batch 35 | Recon Loss: 0.0192
Batch 70 | Recon Loss: 0.0042
Avg Epoch loss: 0.0089

--- Pre-train Epoch 4/100 ---
Batch 0 | Recon Loss: 0.0038
Batch 35 | Recon Loss: 0.0176
Batch 70 | Recon Loss: 0.0034
Avg Epoch loss: 0.0072

--- Pre-train Epoch 5/100 ---
Batch 0 | Recon Loss: 0.0049
Batch 35 | Recon Loss: 0.0038
Batch 70 | Recon Loss: 0.0045
Avg Epoch loss: 0.0069

--- Pre-train Epoch 6/100 ---
Batch 0 | Recon Loss: 0.0035
Batch 35 | Recon Loss: 0.0028
Batch 70 | Recon Loss: 0.0021
Avg Epoch loss: 0.0060

--- Pre-train Epoch 7/100 ---
Batch 0 | Recon Loss: 0.0025
Batch 35 | Recon Loss: 0.0160
Batch 70 | Recon Loss: 0.0081
Avg Epoch loss: 0.0053

--- Pre-train Epoch 8/100 ---
Batch 0 | Recon Loss: 0.0026
Batch 35 | Recon Loss: 0.0098
Batch 70 | Recon Loss: 0.0051
Avg Epoch loss: 0.0052

--- Pre-train Epoch 9/100 ---
Batch 0 | Recon Loss: 0.0024
Batch 35 | Recon Loss: 0.0022
Batch 70 | Recon Loss: 0.0036
Avg Epoch loss: 0.0046

--- Pre-train Epoch 10/100 ---
Batch 0 | Recon Loss: 0.0034
Batch 35 | Recon Loss: 0.0030
Batch 70 | Recon Loss: 0.0015
Avg Epoch loss: 0.0048

--- Pre-train Epoch 11/100 ---
Batch 0 | Recon Loss: 0.0044
Batch 35 | Recon Loss: 0.0049
Batch 70 | Recon Loss: 0.0032
Avg Epoch loss: 0.0046

--- Pre-train Epoch 12/100 ---
Batch 0 | Recon Loss: 0.0058
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0038
Avg Epoch loss: 0.0047

--- Pre-train Epoch 13/100 ---
Batch 0 | Recon Loss: 0.0046
Batch 35 | Recon Loss: 0.0053
Batch 70 | Recon Loss: 0.0025
Avg Epoch loss: 0.0037

--- Pre-train Epoch 14/100 ---
Batch 0 | Recon Loss: 0.0022
Batch 35 | Recon Loss: 0.0172
Batch 70 | Recon Loss: 0.0022
Avg Epoch loss: 0.0038

--- Pre-train Epoch 15/100 ---
Batch 0 | Recon Loss: 0.0022
Batch 35 | Recon Loss: 0.0056
Batch 70 | Recon Loss: 0.0033
Avg Epoch loss: 0.0043

--- Pre-train Epoch 16/100 ---
Batch 0 | Recon Loss: 0.0053
Batch 35 | Recon Loss: 0.0026
Batch 70 | Recon Loss: 0.0149
Avg Epoch loss: 0.0040

--- Pre-train Epoch 17/100 ---
Batch 0 | Recon Loss: 0.0021
Batch 35 | Recon Loss: 0.0034
Batch 70 | Recon Loss: 0.0024
Avg Epoch loss: 0.0038

--- Pre-train Epoch 18/100 ---
Batch 0 | Recon Loss: 0.0030
Batch 35 | Recon Loss: 0.0018
Batch 70 | Recon Loss: 0.0092
Avg Epoch loss: 0.0043

--- Pre-train Epoch 19/100 ---
Batch 0 | Recon Loss: 0.0018
Batch 35 | Recon Loss: 0.0074
Batch 70 | Recon Loss: 0.0040
Avg Epoch loss: 0.0039

--- Pre-train Epoch 20/100 ---
Batch 0 | Recon Loss: 0.0012
Batch 35 | Recon Loss: 0.0027
Batch 70 | Recon Loss: 0.0039
Avg Epoch loss: 0.0029

--- Pre-train Epoch 21/100 ---
Batch 0 | Recon Loss: 0.0027
Batch 35 | Recon Loss: 0.0011
Batch 70 | Recon Loss: 0.0118
Avg Epoch loss: 0.0041

--- Pre-train Epoch 22/100 ---
Batch 0 | Recon Loss: 0.0013
Batch 35 | Recon Loss: 0.0117
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0039

--- Pre-train Epoch 23/100 ---
Batch 0 | Recon Loss: 0.0048
Batch 35 | Recon Loss: 0.0021
Batch 70 | Recon Loss: 0.0065
Avg Epoch loss: 0.0040

--- Pre-train Epoch 24/100 ---
Batch 0 | Recon Loss: 0.0019
Batch 35 | Recon Loss: 0.0019
Batch 70 | Recon Loss: 0.0025
Avg Epoch loss: 0.0037

--- Pre-train Epoch 25/100 ---
Batch 0 | Recon Loss: 0.0011
Batch 35 | Recon Loss: 0.0023
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0042

--- Pre-train Epoch 26/100 ---
Batch 0 | Recon Loss: 0.0015
Batch 35 | Recon Loss: 0.0023
Batch 70 | Recon Loss: 0.0029
Avg Epoch loss: 0.0040

--- Pre-train Epoch 27/100 ---
Batch 0 | Recon Loss: 0.0038
Batch 35 | Recon Loss: 0.0008
Batch 70 | Recon Loss: 0.0022
Avg Epoch loss: 0.0036

--- Pre-train Epoch 28/100 ---
Batch 0 | Recon Loss: 0.0013
Batch 35 | Recon Loss: 0.0071
Batch 70 | Recon Loss: 0.0017
Avg Epoch loss: 0.0029

--- Pre-train Epoch 29/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0072
Batch 70 | Recon Loss: 0.0104
Avg Epoch loss: 0.0029

--- Pre-train Epoch 30/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0052
Batch 70 | Recon Loss: 0.0042
Avg Epoch loss: 0.0032

--- Pre-train Epoch 31/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0019
Batch 70 | Recon Loss: 0.0026
Avg Epoch loss: 0.0031

--- Pre-train Epoch 32/100 ---
Batch 0 | Recon Loss: 0.0022
Batch 35 | Recon Loss: 0.0031
Batch 70 | Recon Loss: 0.0055
Avg Epoch loss: 0.0030

--- Pre-train Epoch 33/100 ---
Batch 0 | Recon Loss: 0.0024
Batch 35 | Recon Loss: 0.0019
Batch 70 | Recon Loss: 0.0015
Avg Epoch loss: 0.0036

--- Pre-train Epoch 34/100 ---
Batch 0 | Recon Loss: 0.0018
Batch 35 | Recon Loss: 0.0111
Batch 70 | Recon Loss: 0.0019
Avg Epoch loss: 0.0034

--- Pre-train Epoch 35/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0016
Batch 70 | Recon Loss: 0.0035
Avg Epoch loss: 0.0031

--- Pre-train Epoch 36/100 ---
Batch 0 | Recon Loss: 0.0015
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0028

--- Pre-train Epoch 37/100 ---
Batch 0 | Recon Loss: 0.0061
Batch 35 | Recon Loss: 0.0030
Batch 70 | Recon Loss: 0.0015
Avg Epoch loss: 0.0033

--- Pre-train Epoch 38/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0008
Batch 70 | Recon Loss: 0.0036
Avg Epoch loss: 0.0030

--- Pre-train Epoch 39/100 ---
Batch 0 | Recon Loss: 0.0021
Batch 35 | Recon Loss: 0.0009
Batch 70 | Recon Loss: 0.0018
Avg Epoch loss: 0.0033

--- Pre-train Epoch 40/100 ---
Batch 0 | Recon Loss: 0.0019
Batch 35 | Recon Loss: 0.0010
Batch 70 | Recon Loss: 0.0059
Avg Epoch loss: 0.0030

--- Pre-train Epoch 41/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0012
Batch 70 | Recon Loss: 0.0031
Avg Epoch loss: 0.0029

--- Pre-train Epoch 42/100 ---
Batch 0 | Recon Loss: 0.0031
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0078
Avg Epoch loss: 0.0034

--- Pre-train Epoch 43/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0016
Batch 70 | Recon Loss: 0.0115
Avg Epoch loss: 0.0030

--- Pre-train Epoch 44/100 ---
Batch 0 | Recon Loss: 0.0042
Batch 35 | Recon Loss: 0.0116
Batch 70 | Recon Loss: 0.0004
Avg Epoch loss: 0.0032

--- Pre-train Epoch 45/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0005
Batch 70 | Recon Loss: 0.0012
Avg Epoch loss: 0.0034

--- Pre-train Epoch 46/100 ---
Batch 0 | Recon Loss: 0.0007
Batch 35 | Recon Loss: 0.0027
Batch 70 | Recon Loss: 0.0016
Avg Epoch loss: 0.0034

--- Pre-train Epoch 47/100 ---
Batch 0 | Recon Loss: 0.0039
Batch 35 | Recon Loss: 0.0005
Batch 70 | Recon Loss: 0.0043
Avg Epoch loss: 0.0027

--- Pre-train Epoch 48/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0009
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0032

--- Pre-train Epoch 49/100 ---
Batch 0 | Recon Loss: 0.0012
Batch 35 | Recon Loss: 0.0103
Batch 70 | Recon Loss: 0.0019
Avg Epoch loss: 0.0033

--- Pre-train Epoch 50/100 ---
Batch 0 | Recon Loss: 0.0011
Batch 35 | Recon Loss: 0.0038
Batch 70 | Recon Loss: 0.0042
Avg Epoch loss: 0.0034

--- Pre-train Epoch 51/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0027
Batch 70 | Recon Loss: 0.0008
Avg Epoch loss: 0.0033

--- Pre-train Epoch 52/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0005
Batch 70 | Recon Loss: 0.0098
Avg Epoch loss: 0.0031

--- Pre-train Epoch 53/100 ---
Batch 0 | Recon Loss: 0.0019
Batch 35 | Recon Loss: 0.0020
Batch 70 | Recon Loss: 0.0020
Avg Epoch loss: 0.0025

--- Pre-train Epoch 54/100 ---
Batch 0 | Recon Loss: 0.0015
Batch 35 | Recon Loss: 0.0007
Batch 70 | Recon Loss: 0.0014
Avg Epoch loss: 0.0030

--- Pre-train Epoch 55/100 ---
Batch 0 | Recon Loss: 0.0016
Batch 35 | Recon Loss: 0.0066
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0028

--- Pre-train Epoch 56/100 ---
Batch 0 | Recon Loss: 0.0019
Batch 35 | Recon Loss: 0.0008
Batch 70 | Recon Loss: 0.0040
Avg Epoch loss: 0.0034

--- Pre-train Epoch 57/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0019
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0027

--- Pre-train Epoch 58/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0012
Batch 70 | Recon Loss: 0.0019
Avg Epoch loss: 0.0027

--- Pre-train Epoch 59/100 ---
Batch 0 | Recon Loss: 0.0009
Batch 35 | Recon Loss: 0.0015
Batch 70 | Recon Loss: 0.0011
Avg Epoch loss: 0.0028

--- Pre-train Epoch 60/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0029
Batch 70 | Recon Loss: 0.0015
Avg Epoch loss: 0.0037

--- Pre-train Epoch 61/100 ---
Batch 0 | Recon Loss: 0.0018
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0007
Avg Epoch loss: 0.0030

--- Pre-train Epoch 62/100 ---
Batch 0 | Recon Loss: 0.0023
Batch 35 | Recon Loss: 0.0111
Batch 70 | Recon Loss: 0.0052
Avg Epoch loss: 0.0033

--- Pre-train Epoch 63/100 ---
Batch 0 | Recon Loss: 0.0006
Batch 35 | Recon Loss: 0.0021
Batch 70 | Recon Loss: 0.0016
Avg Epoch loss: 0.0029

--- Pre-train Epoch 64/100 ---
Batch 0 | Recon Loss: 0.0016
Batch 35 | Recon Loss: 0.0015
Batch 70 | Recon Loss: 0.0022
Avg Epoch loss: 0.0022

--- Pre-train Epoch 65/100 ---
Batch 0 | Recon Loss: 0.0021
Batch 35 | Recon Loss: 0.0009
Batch 70 | Recon Loss: 0.0095
Avg Epoch loss: 0.0028

--- Pre-train Epoch 66/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0006
Batch 70 | Recon Loss: 0.0007
Avg Epoch loss: 0.0025

--- Pre-train Epoch 67/100 ---
Batch 0 | Recon Loss: 0.0028
Batch 35 | Recon Loss: 0.0009
Batch 70 | Recon Loss: 0.0008
Avg Epoch loss: 0.0032

--- Pre-train Epoch 68/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0006
Batch 70 | Recon Loss: 0.0092
Avg Epoch loss: 0.0024

--- Pre-train Epoch 69/100 ---
Batch 0 | Recon Loss: 0.0015
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0050
Avg Epoch loss: 0.0029

--- Pre-train Epoch 70/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0096
Batch 70 | Recon Loss: 0.0008
Avg Epoch loss: 0.0027

--- Pre-train Epoch 71/100 ---
Batch 0 | Recon Loss: 0.0018
Batch 35 | Recon Loss: 0.0008
Batch 70 | Recon Loss: 0.0113
Avg Epoch loss: 0.0027

--- Pre-train Epoch 72/100 ---
Batch 0 | Recon Loss: 0.0044
Batch 35 | Recon Loss: 0.0106
Batch 70 | Recon Loss: 0.0028
Avg Epoch loss: 0.0032

--- Pre-train Epoch 73/100 ---
Batch 0 | Recon Loss: 0.0022
Batch 35 | Recon Loss: 0.0081
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0024

--- Pre-train Epoch 74/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0014
Batch 70 | Recon Loss: 0.0004
Avg Epoch loss: 0.0029

--- Pre-train Epoch 75/100 ---
Batch 0 | Recon Loss: 0.0013
Batch 35 | Recon Loss: 0.0005
Batch 70 | Recon Loss: 0.0046
Avg Epoch loss: 0.0036

--- Pre-train Epoch 76/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0008
Batch 70 | Recon Loss: 0.0022
Avg Epoch loss: 0.0027

--- Pre-train Epoch 77/100 ---
Batch 0 | Recon Loss: 0.0020
Batch 35 | Recon Loss: 0.0014
Batch 70 | Recon Loss: 0.0036
Avg Epoch loss: 0.0032

--- Pre-train Epoch 78/100 ---
Batch 0 | Recon Loss: 0.0014
Batch 35 | Recon Loss: 0.0009
Batch 70 | Recon Loss: 0.0024
Avg Epoch loss: 0.0027

--- Pre-train Epoch 79/100 ---
Batch 0 | Recon Loss: 0.0012
Batch 35 | Recon Loss: 0.0016
Batch 70 | Recon Loss: 0.0113
Avg Epoch loss: 0.0025

--- Pre-train Epoch 80/100 ---
Batch 0 | Recon Loss: 0.0021
Batch 35 | Recon Loss: 0.0004
Batch 70 | Recon Loss: 0.0007
Avg Epoch loss: 0.0033

--- Pre-train Epoch 81/100 ---
Batch 0 | Recon Loss: 0.0020
Batch 35 | Recon Loss: 0.0037
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0025

--- Pre-train Epoch 82/100 ---
Batch 0 | Recon Loss: 0.0011
Batch 35 | Recon Loss: 0.0024
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0025

--- Pre-train Epoch 83/100 ---
Batch 0 | Recon Loss: 0.0017
Batch 35 | Recon Loss: 0.0006
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0023

--- Pre-train Epoch 84/100 ---
Batch 0 | Recon Loss: 0.0006
Batch 35 | Recon Loss: 0.0007
Batch 70 | Recon Loss: 0.0006
Avg Epoch loss: 0.0029

--- Pre-train Epoch 85/100 ---
Batch 0 | Recon Loss: 0.0025
Batch 35 | Recon Loss: 0.0005
Batch 70 | Recon Loss: 0.0011
Avg Epoch loss: 0.0021

--- Pre-train Epoch 86/100 ---
Batch 0 | Recon Loss: 0.0007
Batch 35 | Recon Loss: 0.0017
Batch 70 | Recon Loss: 0.0008
Avg Epoch loss: 0.0019

--- Pre-train Epoch 87/100 ---
Batch 0 | Recon Loss: 0.0011
Batch 35 | Recon Loss: 0.0017
Batch 70 | Recon Loss: 0.0010
Avg Epoch loss: 0.0027

--- Pre-train Epoch 88/100 ---
Batch 0 | Recon Loss: 0.0008
Batch 35 | Recon Loss: 0.0013
Batch 70 | Recon Loss: 0.0009
Avg Epoch loss: 0.0021

--- Pre-train Epoch 89/100 ---
Batch 0 | Recon Loss: 0.0009
Batch 35 | Recon Loss: 0.0056
Batch 70 | Recon Loss: 0.0162
Avg Epoch loss: 0.0028

--- Pre-train Epoch 90/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0099
Batch 70 | Recon Loss: 0.0015
Avg Epoch loss: 0.0034

--- Pre-train Epoch 91/100 ---
Batch 0 | Recon Loss: 0.0009
Batch 35 | Recon Loss: 0.0027
Batch 70 | Recon Loss: 0.0019
Avg Epoch loss: 0.0026

--- Pre-train Epoch 92/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0033
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0024

--- Pre-train Epoch 93/100 ---
Batch 0 | Recon Loss: 0.0033
Batch 35 | Recon Loss: 0.0028
Batch 70 | Recon Loss: 0.0013
Avg Epoch loss: 0.0030

--- Pre-train Epoch 94/100 ---
Batch 0 | Recon Loss: 0.0030
Batch 35 | Recon Loss: 0.0018
Batch 70 | Recon Loss: 0.0009
Avg Epoch loss: 0.0024

--- Pre-train Epoch 95/100 ---
Batch 0 | Recon Loss: 0.0010
Batch 35 | Recon Loss: 0.0027
Batch 70 | Recon Loss: 0.0111
Avg Epoch loss: 0.0025

--- Pre-train Epoch 96/100 ---
Batch 0 | Recon Loss: 0.0014
Batch 35 | Recon Loss: 0.0014
Batch 70 | Recon Loss: 0.0030
Avg Epoch loss: 0.0031

--- Pre-train Epoch 97/100 ---
Batch 0 | Recon Loss: 0.0014
Batch 35 | Recon Loss: 0.0022
Batch 70 | Recon Loss: 0.0027
Avg Epoch loss: 0.0036

--- Pre-train Epoch 98/100 ---
Batch 0 | Recon Loss: 0.0022
Batch 35 | Recon Loss: 0.0030
Batch 70 | Recon Loss: 0.0008
Avg Epoch loss: 0.0022

--- Pre-train Epoch 99/100 ---
Batch 0 | Recon Loss: 0.0019
Batch 35 | Recon Loss: 0.0026
Batch 70 | Recon Loss: 0.0009
Avg Epoch loss: 0.0027

--- Pre-train Epoch 100/100 ---
Batch 0 | Recon Loss: 0.0014
Batch 35 | Recon Loss: 0.0068
Batch 70 | Recon Loss: 0.0017
Avg Epoch loss: 0.0027
--- Pre-training Finished ---
Saving encoder weights to /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Trained_models/pretrained_ae_encoder.pth
Job Finished.

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27059639: <pretain_AE_job> in cluster <dcc> Done

Job <pretain_AE_job> was submitted from host <gbarlogin1> by user <s214776> in cluster <dcc> at Mon Nov 17 21:04:53 2025
Job was executed on host(s) <4*n-62-13-18>, in queue <gpul40s>, as user <s214776> in cluster <dcc> at Mon Nov 17 22:09:53 2025
</zhome/d2/4/167803> was used as the home directory.
</zhome/d2/4/167803/Desktop/Deep_project/02456-final-project> was used as the working directory.
Started at Mon Nov 17 22:09:53 2025
Terminated at Tue Nov 18 02:08:49 2025
Results reported at Tue Nov 18 02:08:49 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
### --- Job Name ---
#BSUB -J pretain_AE_job

### --- Log files ---
#BSUB -o /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_%J.out
#BSUB -e /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_%J.err
### --- Resource Requests ---
#BSUB -q gpul40s            # Request GPU queue
#BSUB -gpu "num=1:mode=exclusive_process" # Request 1 GPU, all to myself
#BSUB -n 4                    # Request 4 CPU cores
#BSUB -R "rusage[mem=12GB]"   # Request 16GB memory
#BSUB -W 04:00                # 4 hour runtime limit

### --- Setup Environment ---
echo "Loading CUDA module..."
module load cuda/11.6         # Load CUDA module

echo "Loading Conda..."
# This is the full, correct path to your environment
source /zhome/d2/4/167803/miniforge3/bin/activate MBML
echo "Environment 'MBML' activated."

### --- Run Script ---
echo "Starting Python script..."
python /zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Model/pretrain_AE.py

echo "Job Finished."
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   40679.00 sec.
    Max Memory :                                 1454 MB
    Average Memory :                             1234.75 MB
    Total Requested Memory :                     49152.00 MB
    Delta Memory :                               47698.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   14338 sec.
    Turnaround time :                            18236 sec.

The output (if any) is above this job summary.



PS:

Read file </zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/logs/pretain_AE_job_27059639.err> for stderr output of this job.

