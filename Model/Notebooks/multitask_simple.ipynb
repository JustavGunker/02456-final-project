{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f50ce5f",
   "metadata": {},
   "source": [
    "### Semi-supervised learning\n",
    "## Multi-tasking \n",
    "Data taken from https://www.kaggle.com/datasets/prathamgrover/3d-liver-segmentation?resource=download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cef25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "cd= Path.cwd().parent.parent\n",
    "sys.path.append(str(cd))\n",
    "\n",
    "from func.utill import DiceLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff699e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_nii_sizes(folder_path):\n",
    "    nii_files = glob.glob(os.path.join(folder_path, \"*.nii\"))\n",
    "    for file in nii_files:\n",
    "        img = nib.load(file)\n",
    "        data = img.get_fdata()\n",
    "        print(f\"File: {os.path.basename(file)}, Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03176e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SHAPE = (64, 64, 64) # ( D, H, W)\n",
    "NUM_CLASSES = 3  # Background, Segment 1, Segment 2\n",
    "LATENT_DIM = 256 # RNN batch\n",
    "BATCH_SIZE = 4\n",
    "TIME_STEPS = 10 # Time series size \n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A 3D Convolutional block: Conv3D -> BatchNorm -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Seg_decoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.up_seg1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2) # -> 64x14x14x14\n",
    "        self.dec_seg1 = ConvBlock(128, 64) # add skip connection 64+64= 128\n",
    "        \n",
    "        self.up_seg2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2) # 32x28x28x28\n",
    "        self.dec_seg2 = ConvBlock(64, 32) # add skip connection 32+32= 64\n",
    "        \n",
    "        self.out_seg = nn.Conv3d(32, num_classes, kernel_size=1) # Output segmentation\n",
    "        \n",
    "    def forward(self, b , s1, s2):\n",
    "         # segmentation decoder forward step\n",
    "        us1 = self.up_seg1(b) # -> Bx64x14x14x14\n",
    "        ds1 = self.dec_seg1(torch.cat([us1, s2], dim=1)) # Concat skip 2\n",
    "        \n",
    "        us2 = self.up_seg2(ds1) # -> Bx32x28x28x28\n",
    "        ds2 = self.dec_seg2(torch.cat([us2, s1], dim=1)) # Concat skip 1\n",
    "        us3 = self.out_seg(ds2) \n",
    "        return us3\n",
    "    \n",
    "class Recon_decoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.up_recon1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2) # ->64x14x14x14\n",
    "        self.dec_recon1 = ConvBlock(128, 64)\n",
    "\n",
    "        self.up_recon2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2) # -> 32x28x28x28\n",
    "        self.dec_recon2 = ConvBlock(64, 32)\n",
    "\n",
    "        self.out_recon = nn.Sequential(\n",
    "            nn.Conv3d(32, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, b, s1, s2):\n",
    "        ur1 = self.up_recon1(b)   # -> Bx64x14x14x14\n",
    "        dr1 = self.dec_recon1(torch.cat([ur1, s2], dim=1))\n",
    "        \n",
    "        ur2 = self.up_recon2(dr1) # -> Bx3x28x28x28\n",
    "        dr2 = self.dec_recon2(torch.cat([ur2, s1], dim=1))\n",
    "\n",
    "        ur3 = self.out_recon(dr2) # -> Bx1x28x28x28\n",
    "\n",
    "        return ur3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d40d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3, latent_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Commen encoder\n",
    "        # 1x28x28x28\n",
    "        self.enc1 = ConvBlock(in_channels, 32) # -> 32x28x28x28\n",
    "        self.pool1 = nn.MaxPool3d(2) # -> 32x14x14x14\n",
    "        \n",
    "        self.enc2 = ConvBlock(32, 64) # -> 64x14x14x14\n",
    "        self.pool2 = nn.MaxPool3d(2) # -> 64x7x7x7\n",
    "        \n",
    "        # Bottleneck \n",
    "        self.bottleneck = ConvBlock(64, 128) # -> 128x7x7x7\n",
    "        \n",
    "        # Feature vector for rnn input\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.to_latent_vec = nn.Linear(128, latent_dim) # -> Bx256x\n",
    "\n",
    "        # First decoder head for segmentation with skipped connect\n",
    "        self.seg_decoder = Seg_decoder(num_classes=num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Second decoder head reconstruction without skipped\n",
    "        self.recon_decoder = Recon_decoder(in_channels=in_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # commen encoder\n",
    "        s1 = self.enc1(x)       # -> Bx32x28x28x28]\n",
    "        p1 = self.pool1(s1)     # -> Bx32x14x14x14\n",
    "        \n",
    "        s2 = self.enc2(p1)      # -> Bx64x14x14x14\n",
    "        p2 = self.pool2(s2)     # -> Bx64x7x7x7x\n",
    "        \n",
    "        # bottleneck -> could be variational\n",
    "        b = self.bottleneck(p2) # [B, 128, 7, 7, 7]\n",
    "\n",
    "        # Vectorize bottleneck output \n",
    "        pooled_vec = self.global_pool(b).view(b.size(0), -1) # -<Bx128\n",
    "        latent_z = self.to_latent_vec(pooled_vec)            # ->Bx256\n",
    "\n",
    "        # Segmentation decoder head with skips\n",
    "        seg_output = self.seg_decoder(b, s1, s2)\n",
    "        seg_output = self.sigmoid(seg_output)\n",
    "\n",
    "        # Reconstruction decoder head without skips\n",
    "        recon_output = self.recon_decoder(b, s1, s2)\n",
    "        \n",
    "        return seg_output, recon_output, latent_z\n",
    "\n",
    "\n",
    "# Temporal model -> could add more dimension \n",
    "class TemporalTracker(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True \n",
    "        )\n",
    "\n",
    "        # predict t+1\n",
    "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, z_sequence):\n",
    "        # z_sequence shape -> Batch x Time_Steps x latent_dim\n",
    "        lstm_out, _ = self.lstm(z_sequence)\n",
    "        \n",
    "        # only care about t+1\n",
    "        last_step_out = lstm_out[:, -1, :] # -1 last time step +1 \n",
    "        \n",
    "        # fc layer for prediction\n",
    "        prediction = self.fc(last_step_out)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70d6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiverDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Made by AI\n",
    "    Custom PyTorch Dataset for the 3D Liver Segmentation data.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, label_dir, target_size=INPUT_SHAPE):\n",
    "        print(image_dir)\n",
    "        print(label_dir)\n",
    "        # --- THIS IS THE CORRECTED PART (looking for .nii) ---\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"imagesTr\",\"*.nii\")))\n",
    "        self.label_paths = sorted(glob.glob(os.path.join(label_dir, \"labelsTr\" , \"*.nii\")))      \n",
    "        self.target_size = target_size # (D, H, W)\n",
    "        \n",
    "        # Ensure we have matched pairs\n",
    "        assert len(self.image_paths) > 0, f\"No images found in {image_dir}\"\n",
    "        assert len(self.label_paths) > 0, f\"No labels found in {label_dir}\"\n",
    "        assert len(self.image_paths) == len(self.label_paths), \\\n",
    "            f\"Found {len(self.image_paths)} images but {len(self.label_paths)} labels.\"\n",
    "        \n",
    "        print(f\"Found {len(self.image_paths)} image/label pairs.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        data = data - torch.min(data)\n",
    "        data = data / torch.max(data)\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Load NIfTI files (nibabel handles .nii and .nii.gz the same way)\n",
    "        img_nii = nib.load(self.image_paths[idx])\n",
    "        lbl_nii = nib.load(self.label_paths[idx])\n",
    "        \n",
    "        # 2. Get data as numpy array and convert to tensor\n",
    "        img_tensor = torch.from_numpy(img_nii.get_fdata()).float().permute(2, 1, 0).unsqueeze(0)\n",
    "        lbl_tensor = torch.from_numpy(lbl_nii.get_fdata()).long().permute(2, 1, 0).unsqueeze(0)\n",
    "\n",
    "        # 3. Resize\n",
    "        img_resized = F.interpolate(img_tensor.unsqueeze(0), \n",
    "                                    size=self.target_size, \n",
    "                                    mode='trilinear', \n",
    "                                    align_corners=False).squeeze(0)\n",
    "        \n",
    "        lbl_resized = F.interpolate(lbl_tensor.float().unsqueeze(0), \n",
    "                                    size=self.target_size, \n",
    "                                    mode='nearest').squeeze(0).long()\n",
    "\n",
    "        # 4. Normalize image\n",
    "        img_resized = self.normalize(img_resized)\n",
    "\n",
    "        # Squeeze the channel dim from the label\n",
    "        lbl_resized = lbl_resized.squeeze(0) \n",
    "\n",
    "        return img_resized, lbl_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2e3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiverUnlabeledDataset(Dataset):\n",
    "    \"\"\"\n",
    "    made by AI\n",
    "    Custom PyTorch Dataset for 3D Liver UNLABELED images.\n",
    "    Loads only images and returns them as a 1-item tuple.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, target_size=INPUT_SHAPE, subfolder=\"imagesTr\"):\n",
    "        # Assumes unlabeled images are in a folder like 'imagesUnlabeledTr'\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, subfolder, \"*.nii\")))\n",
    "        self.target_size = target_size # (D, H, W)\n",
    "        \n",
    "        assert len(self.image_paths) > 0, f\"No unlabeled images found in {os.path.join(image_dir, subfolder)}\"\n",
    "        print(f\"Found {len(self.image_paths)} unlabeled images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        data = data - torch.min(data)\n",
    "        data = data / torch.max(data)\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Load NIfTI file\n",
    "        img_nii = nib.load(self.image_paths[idx])\n",
    "        \n",
    "        # 2. Get data as numpy array and convert to tensor\n",
    "        img_tensor = torch.from_numpy(img_nii.get_fdata()).float().permute(2, 1, 0).unsqueeze(0)\n",
    "\n",
    "        # 3. Resize\n",
    "        img_resized = F.interpolate(img_tensor.unsqueeze(0), \n",
    "                                    size=self.target_size, \n",
    "                                    mode='trilinear', \n",
    "                                    align_corners=False).squeeze(0)\n",
    "        \n",
    "        # 4. Normalize image\n",
    "        img_resized = self.normalize(img_resized)\n",
    "\n",
    "        # 5. Return as a 1-item tuple\n",
    "        # This is important so the loop `(x_unlabeled)` unpacks correctly\n",
    "        return (img_resized,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4989e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "/zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Task03_Liver_rs\n",
      "/zhome/d2/4/167803/Desktop/Deep_project/02456-final-project/Task03_Liver_rs\n",
      "Found 28 image/label pairs.\n",
      "--- success ---\n",
      "Found 119 unlabeled images.\n",
      "--- success ---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "DATA_DIR = \"./Task03_Liver_rs\" \n",
    "# This one path points to the root directory (e.g., ./Task03_Liver_rs)\n",
    "data_root_folder = Path.cwd().parent.parent / DATA_DIR\n",
    "\n",
    "\n",
    "try:\n",
    "    # labeled set\n",
    "    labeled_dataset = LiverDataset(image_dir=data_root_folder, label_dir=data_root_folder, target_size= INPUT_SHAPE)\n",
    "    \n",
    "    #DataLoader for labeled data\n",
    "    labeled_loader = DataLoader(\n",
    "        dataset=labeled_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "\n",
    "        shuffle=True\n",
    "    )\n",
    "    print(\"--- success ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Labeled dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "\n",
    "    unlabeled_dataset = LiverUnlabeledDataset(\n",
    "        image_dir=data_root_folder, \n",
    "        subfolder=\"imagesUnlabelledTr\",\n",
    "        target_size= INPUT_SHAPE\n",
    "    )\n",
    "    \n",
    "    # \n",
    "    unlabeled_loader = DataLoader(\n",
    "        dataset=unlabeled_dataset,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True\n",
    "    )\n",
    "    print(\"--- success ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Unlabeled dataset: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4309ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training the MultiTaskNet on Liver Data ---\n",
      "\n",
      "--- Epoch 1/31 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m optimizer_model.zero_grad()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# forward pass on labeled data for both seg and recon\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m seg_out, recon_out_labeled, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_labeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# segmentation losses\u001b[39;00m\n\u001b[32m     39\u001b[39m loss_seg_cross = loss_fn_seg_cross(seg_out, y_seg_target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mMultiTaskNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     41\u001b[39m latent_z = \u001b[38;5;28mself\u001b[39m.to_latent_vec(pooled_vec)            \u001b[38;5;66;03m# ->Bx256\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Segmentation decoder head with skips\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m seg_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseg_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m seg_output = \u001b[38;5;28mself\u001b[39m.sigmoid(seg_output)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Reconstruction decoder head without skips\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mSeg_decoder.forward\u001b[39m\u001b[34m(self, b, s1, s2)\u001b[39m\n\u001b[32m     37\u001b[39m ds1 = \u001b[38;5;28mself\u001b[39m.dec_seg1(torch.cat([us1, s2], dim=\u001b[32m1\u001b[39m)) \u001b[38;5;66;03m# Concat skip 2\u001b[39;00m\n\u001b[32m     39\u001b[39m us2 = \u001b[38;5;28mself\u001b[39m.up_seg2(ds1) \u001b[38;5;66;03m# -> Bx32x28x28x28\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m ds2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdec_seg2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mus2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Concat skip 1\u001b[39;00m\n\u001b[32m     41\u001b[39m us3 = \u001b[38;5;28mself\u001b[39m.out_seg(ds2) \n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m us3\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mConvBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/conv.py:608\u001b[39m, in \u001b[36mConv3d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MBML/lib/python3.12/site-packages/torch/nn/modules/conv.py:603\u001b[39m, in \u001b[36mConv3d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv3d(\n\u001b[32m    593\u001b[39m         F.pad(\n\u001b[32m    594\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    601\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    602\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # start model\n",
    "    model = MultiTaskNet(\n",
    "        in_channels=1, \n",
    "        num_classes=NUM_CLASSES, \n",
    "        latent_dim=LATENT_DIM  \n",
    "    ).to(device)\n",
    "\n",
    "    # define loss and optimizer\n",
    "    loss_fn_seg_dice = DiceLoss(num_classes= NUM_CLASSES)\n",
    "    loss_fn_seg_cross = nn.CrossEntropyLoss()\n",
    "    loss_fn_recon = nn.MSELoss()\n",
    "    optimizer_model = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"--- Training the MultiTaskNet on Liver Data ---\")\n",
    "    NUM_EPOCHS = 31\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "        \n",
    "        model.train() \n",
    "        \n",
    "        # iterate over both loaders\n",
    "        for batch_idx, ((x_labeled, y_seg_target), (x_unlabeled)) in \\\n",
    "                enumerate(zip(labeled_loader, itertools.cycle(unlabeled_loader))):\n",
    "            \n",
    "            # Move all data to device\n",
    "            x_labeled = x_labeled.to(device)\n",
    "            y_seg_target = y_seg_target.to(device)\n",
    "            x_unlabeled = x_unlabeled\n",
    "            x_unlabeled = x_unlabeled[0]\n",
    "\n",
    "            optimizer_model.zero_grad()\n",
    "            \n",
    "            # forward pass on labeled data for both seg and recon\n",
    "            seg_out, recon_out_labeled, _ = model(x_labeled)\n",
    "            \n",
    "            # segmentation losses\n",
    "            loss_seg_cross = loss_fn_seg_cross(seg_out, y_seg_target)\n",
    "            \n",
    "            total_loss_seg = loss_seg_cross * 1.0\n",
    "            loss_seg_dice = 0.0\n",
    "            \n",
    "            # add dice loss if cross entropy is low enough\n",
    "            if loss_seg_cross.item() < 0.6:\n",
    "                dice_loss_component = loss_fn_seg_dice(seg_out, y_seg_target)\n",
    "                total_loss_seg = total_loss_seg + (dice_loss_component * 1)\n",
    "                loss_seg_dice = dice_loss_component.item()\n",
    "                \n",
    "            # labeled recon loss\n",
    "            loss_recon_labeled = loss_fn_recon(recon_out_labeled, x_labeled)\n",
    "                \n",
    "            # Forward pass only on unlabeled data for recon\n",
    "            _ , recon_out_unlabeled, _ = model(x_unlabeled)\n",
    "            \n",
    "            # unlabeled recon loss\n",
    "            loss_recon_unlabeled = loss_fn_recon(recon_out_unlabeled, x_unlabeled)\n",
    "            \n",
    "            # Total recon loss\n",
    "            total_loss_recon = loss_recon_labeled + loss_recon_unlabeled\n",
    "            \n",
    "            # Total combined loss\n",
    "            total_loss = total_loss_seg + (total_loss_recon * 0.5) \n",
    "                \n",
    "            total_loss.backward()\n",
    "            optimizer_model.step()\n",
    "            \n",
    "            # Udate Logging\n",
    "            if batch_idx % 30 == 0:\n",
    "                if loss_seg_cross.item() > 0.6:\n",
    "                    print(f\"Batch {batch_idx}/{len(labeled_loader)} | Total Loss: {total_loss.item():.4f} | Recon Loss (Total): {total_loss_recon.item():.4f} | CE Loss (Labeled): {loss_seg_cross.item():.4f} (Dice not active)\")\n",
    "                else:\n",
    "                    print(f\"Batch {batch_idx}/{len(labeled_loader)} | Total Loss: {total_loss.item():.4f} | Recon Loss (Total): {total_loss_recon.item():.4f} | CE Loss (Labeled): {loss_seg_cross.item():.4f} | DICE Loss (Labeled): {loss_seg_dice:.4f}\")\n",
    "            \n",
    "            # visualization update\n",
    "            if epoch % 10 == 0 and batch_idx % 30 == 0:\n",
    "                print(\"--- Visualizing first training batch (Labeled Data) ---\")\n",
    "                visualize_slices(x_labeled, y_seg_target, recon_out_labeled, seg_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
